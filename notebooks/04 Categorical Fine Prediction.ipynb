{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUM</th>\n",
       "      <th>FACILITY</th>\n",
       "      <th>DATE</th>\n",
       "      <th>FINE</th>\n",
       "      <th>NARRATIVE</th>\n",
       "      <th>TRIGRAMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20008964</td>\n",
       "      <td>FREMONT HEALTHCARE CENTER</td>\n",
       "      <td>2012-02-01</td>\n",
       "      <td>750.0</td>\n",
       "      <td>F323 483.25(h) FREE OF ACCIDENT HAZARDS/SUPERV...</td>\n",
       "      <td>[hazard_supervision_device, device_prevent_acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20009068</td>\n",
       "      <td>WILLOW TREE NURSING CENTER</td>\n",
       "      <td>2012-03-02</td>\n",
       "      <td>750.0</td>\n",
       "      <td>Title 22 72520 (a) If a patient of a skilled n...</td>\n",
       "      <td>[skilled_nursing_facility, hospital_define_sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20009069</td>\n",
       "      <td>KINDRED NURSING AND REHABILITATION - YGNACIO V...</td>\n",
       "      <td>2012-03-02</td>\n",
       "      <td>750.0</td>\n",
       "      <td>483.12(b) (3) Permitting Resident to Return to...</td>\n",
       "      <td>[bed_hold_period, facility_immediately_availab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20009078</td>\n",
       "      <td>BAY VIEW REHABILITATION HOSPITAL, LLC</td>\n",
       "      <td>2012-03-05</td>\n",
       "      <td>37500.0</td>\n",
       "      <td>483.25 PROVIDE CARE/SERVICES FOR HIGHEST WELL ...</td>\n",
       "      <td>[service_high_beingeach, facility_provide_nece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20009082</td>\n",
       "      <td>LONE TREE CONVALESCENT HOSPITAL</td>\n",
       "      <td>2012-03-06</td>\n",
       "      <td>600.0</td>\n",
       "      <td>T22 DIV5 CH3 ART3-72311(a)(1)(A) Nursing Servi...</td>\n",
       "      <td>[nursing_service_shall, include_limit_followin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        NUM                                           FACILITY        DATE  \\\n",
       "0  20008964                          FREMONT HEALTHCARE CENTER  2012-02-01   \n",
       "1  20009068                         WILLOW TREE NURSING CENTER  2012-03-02   \n",
       "2  20009069  KINDRED NURSING AND REHABILITATION - YGNACIO V...  2012-03-02   \n",
       "3  20009078              BAY VIEW REHABILITATION HOSPITAL, LLC  2012-03-05   \n",
       "4  20009082                    LONE TREE CONVALESCENT HOSPITAL  2012-03-06   \n",
       "\n",
       "      FINE                                          NARRATIVE  \\\n",
       "0    750.0  F323 483.25(h) FREE OF ACCIDENT HAZARDS/SUPERV...   \n",
       "1    750.0  Title 22 72520 (a) If a patient of a skilled n...   \n",
       "2    750.0  483.12(b) (3) Permitting Resident to Return to...   \n",
       "3  37500.0  483.25 PROVIDE CARE/SERVICES FOR HIGHEST WELL ...   \n",
       "4    600.0  T22 DIV5 CH3 ART3-72311(a)(1)(A) Nursing Servi...   \n",
       "\n",
       "                                            TRIGRAMS  \n",
       "0  [hazard_supervision_device, device_prevent_acc...  \n",
       "1  [skilled_nursing_facility, hospital_define_sec...  \n",
       "2  [bed_hold_period, facility_immediately_availab...  \n",
       "3  [service_high_beingeach, facility_provide_nece...  \n",
       "4  [nursing_service_shall, include_limit_followin...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 10\n",
    "\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "data = pd.read_csv(\"../data/interim/trigrams3.csv\")\n",
    "data = data.drop(['Unnamed: 0'], axis=1)\n",
    "data['TRIGRAMS'] = data['TRIGRAMS'].apply(literal_eval)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('hazard_supervision_device device_prevent_accident facility_violate_regulation receive_adequate_super',\n",
       " 'skilled_nursing_facility hospital_define_section skilled_nursing_facility patient_bedhold_seven faci',\n",
       " 'bed_hold_period facility_immediately_availability resident-_require_service facility_ii_eligible fac')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a corpus of strings out of the trigram column in the main database\n",
    "\n",
    "corpus = [' '.join(data.loc[row, 'TRIGRAMS']) for row in range(len(data))] \n",
    "corpus[0][0:100], corpus[1][0:100], corpus[2][0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Generate the data for the $1,000 categorization problem</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that will convert the corpus into a vectorized bag of words, then apply it.\n",
    "# The function also generates a binary outcome variable that is 1 if the fine was $1,000 or more.\n",
    "\n",
    "def make_xy(data, vectorizer=None):\n",
    "    #Your code here    \n",
    "    if vectorizer is None:\n",
    "        vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    X = X.tocsc()  # some versions of sklearn return COO format\n",
    "    y = (data.FINE > 1000).values.astype(np.int)\n",
    "    return X, y\n",
    "X, y = make_xy(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:blue\">Multinomial Naive Bayes predicting if fine was $1,000 or more</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['training score:', 0.867195242814668, 'test score:', 0.7734104046242775, 'F1 Score', 0.832764505119454, 'naive:', 0.7270204647936177]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "foo = MultinomialNB()\n",
    "foo.fit(X_train, y_train)\n",
    "pred1 = foo.predict(X_train)\n",
    "pred2 = foo.predict(X_test)\n",
    "score1_nb1 = metrics.accuracy_score(y_train, pred1)\n",
    "score2_nb1 = metrics.accuracy_score(y_test, pred2)\n",
    "f1score_nb1 = metrics.f1_score(y_test, pred2)\n",
    "naive_nb1 = sum(data.FINE > 1000) / sum(data.FINE > -1)\n",
    "\n",
    "print([\"training score:\", score1_nb1, \"test score:\", score2_nb1, \n",
    "       \"F1 Score\", f1score_nb1, \"naive:\", naive_nb1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">Random Forest Generator predicting if fine was $1,000 or more</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jason GL\\Anaconda3JGL\\envs\\biosphere\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['training score:', 0.7413280475718533, 'test score:', 0.7086705202312139, 'F1 score:', 0.8290366350067843, 'naive:', 0.7270204647936177]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "foo = RandomForestClassifier(max_depth = 4, random_state=48)\n",
    "foo.fit(X_train, y_train)\n",
    "pred1 = foo.predict(X_train)\n",
    "pred2 = foo.predict(X_test)\n",
    "score1_rf1 = foo.score(X_train, y_train)\n",
    "score2_rf1 = foo.score(X_test, y_test)\n",
    "f1score_rf1 = metrics.f1_score(y_test, pred2)\n",
    "naive_rf1 = sum(data.FINE > 1000) / sum(data.FINE > -1)\n",
    "\n",
    "print([\"training score:\", score1_rf1, \"test score:\", score2_rf1, \n",
    "       \"F1 score:\", f1score_rf1, \"naive:\", naive_rf1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#3cb371\">Gradient Boosting Machine predicting if fine was $1,000 or more</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['training score:', 0.9147670961347869, 'test score:', 0.8335260115606936, 'Naive Model:', 0.7270204647936177]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "foo = GradientBoostingClassifier(random_state=48)\n",
    "foo.fit(X_train, y_train)\n",
    "pred1 = foo.predict(X_train)\n",
    "pred2 = foo.predict(X_test)\n",
    "score1_gb1 = foo.score(X_train, y_train)\n",
    "score2_gb1 = foo.score(X_test, y_test)\n",
    "f1score_gb1 = metrics.f1_score(y_test, pred2)\n",
    "naive_gb1 = sum(data.FINE > 1000) / sum(data.FINE > -1)\n",
    "\n",
    "print([\"training score:\", score1_gb1, \"test score:\", score2_gb1, \"Naive Model:\", naive_gb1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Generate the data for the $5,000 categorization problem</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that will convert the corpus into a vectorized bag of words, then apply it.\n",
    "# The function also generates a binary outcome variable that is 1 if the fine was $5,000 or more.\n",
    "\n",
    "def make_xy(data, vectorizer=None):\n",
    "    #Your code here    \n",
    "    if vectorizer is None:\n",
    "        vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    X = X.tocsc()  # some versions of sklearn return COO format\n",
    "    y = (data.FINE > 5000).values.astype(np.int)\n",
    "    return X, y\n",
    "X, y = make_xy(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:blue\">Multinomial Naive Bayes predicting if fine was $5,000 or more</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['training score:', 0.8632309217046581, 'test score:', 0.7780346820809249, 'F1 Score', 0.6631578947368421, 'naive:', 0.269857787027402]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "foo = MultinomialNB()\n",
    "foo.fit(X_train, y_train)\n",
    "pred1 = foo.predict(X_train)\n",
    "pred2 = foo.predict(X_test)\n",
    "score1_nb2 = metrics.accuracy_score(y_train, pred1)\n",
    "score2_nb2 = metrics.accuracy_score(y_test, pred2)\n",
    "f1score_nb2 = metrics.f1_score(y_test, pred2)\n",
    "naive_nb2 = sum(data.FINE > 5000) / sum(data.FINE > -1)\n",
    "\n",
    "print([\"training score:\", score1_nb2, \"test score:\", score2_nb2, \n",
    "       \"F1 Score\", f1score_nb2, \"naive:\", naive_nb2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">Random Forest Generator predicting if fine was $5,000 or more</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['training score:', 0.8166501486620417, 'test score:', 0.7884393063583816, 'F1 score:', 0.39202657807308966, 'naive:', 0.269857787027402]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jason GL\\Anaconda3JGL\\envs\\biosphere\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "foo = RandomForestClassifier(max_depth = 4, random_state=48)\n",
    "foo.fit(X_train, y_train)\n",
    "pred1 = foo.predict(X_train)\n",
    "pred2 = foo.predict(X_test)\n",
    "score1_rf2 = foo.score(X_train, y_train)\n",
    "score2_rf2 = foo.score(X_test, y_test)\n",
    "f1score_rf2 = metrics.f1_score(y_test, pred2)\n",
    "naive_rf2 = sum(data.FINE > 5000) / sum(data.FINE > -1)\n",
    "\n",
    "print([\"training score:\", score1_rf2, \"test score:\", score2_rf2,\n",
    "       \"F1 score:\", f1score_rf2, \"naive:\", naive_rf2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#3cb371\">Gradient Boosting Machine predicting if fine was $5,000 or more</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['training score:', 0.9767096134786918, 'test score:', 0.945664739884393, 'F1 Score', 0.6631578947368421, 'Naive Model:', 0.269857787027402]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "foo = GradientBoostingClassifier(random_state=48)\n",
    "foo.fit(X_train, y_train)\n",
    "pred1 = foo.predict(X_train)\n",
    "pred2 = foo.predict(X_test)\n",
    "score1_gb2 = foo.score(X_train, y_train)\n",
    "score2_gb2 = foo.score(X_test, y_test)\n",
    "f1score_gb2 = metrics.f1_score(y_test, pred2)\n",
    "naive_gb2 = sum(data.FINE > 5000) / sum(data.FINE > -1)\n",
    "\n",
    "print([\"training score:\", score1_gb2, \"test score:\", score2_gb2, \n",
    "       \"F1 Score\", f1score_nb2, \"Naive Model:\", naive_gb2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Summary of performance of categorical models</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>GradientBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train &gt;$1,000</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test &gt;$1,000</th>\n",
       "      <td>0.773</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 &gt;$1,000</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive &gt;$1,000</th>\n",
       "      <td>0.727</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train &gt;$5,000</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test &gt;$5,000</th>\n",
       "      <td>0.778</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 &gt;$5,000</th>\n",
       "      <td>0.663</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive &gt;$5,000</th>\n",
       "      <td>0.270</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MultinomialNB  RandomForest  GradientBoost\n",
       "Train >$1,000          0.867         0.741          0.915\n",
       "Test >$1,000           0.773         0.709          0.834\n",
       "F1 >$1,000             0.833         0.829          0.889\n",
       "Naive >$1,000          0.727         0.727          0.727\n",
       "Train >$5,000          0.863         0.817          0.977\n",
       "Test >$5,000           0.778         0.788          0.946\n",
       "F1 >$5,000             0.663         0.392          0.899\n",
       "Naive >$5,000          0.270         0.270          0.270"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pd.DataFrame(\n",
    "    {\"MultinomialNB\": [score1_nb1, score2_nb1, f1score_nb1, naive_nb1,\n",
    "                      score1_nb2, score2_nb2, f1score_nb2, naive_nb2],\n",
    "    \"RandomForest\": [score1_rf1, score2_rf1, f1score_rf1, naive_rf1,\n",
    "                    score1_rf2, score2_rf2, f1score_rf2, naive_rf2],\n",
    "    \"GradientBoost\": [score1_gb1, score2_gb1, f1score_gb1, naive_gb1,\n",
    "                     score1_gb2, score2_gb2, f1score_gb2, naive_gb2]})\n",
    "summary.index = ['Train >$1,000', 'Test >$1,000', 'F1 >$1,000', 'Naive >$1,000',\n",
    "                'Train >$5,000', 'Test >$5,000', 'F1 >$5,000', 'Naive >$5,000']\n",
    "summary.round(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
